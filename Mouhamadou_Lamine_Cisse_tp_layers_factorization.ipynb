{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["\n","* Rename this notebook as PRENOM_NOM_TP_LAYER_FACTORIZATION.ipynb\n","* Delivery deadline is March the 21th\n","\n"],"metadata":{"id":"H6T4LjkWk5Ex"}},{"cell_type":"markdown","source":["The final output of the exercise will be the following pandas dataframe"],"metadata":{"id":"raGXLnQGy-BL"}},{"cell_type":"code","source":["import pandas as pd\n","results = pd.DataFrame(columns = ['model', 'matrix/Tucker rank', 'uncompressed_layer_size', 'compressed_layer_size', 'compressed_layer_size/uncompressed_layer_size', 'accuracy'])\n","results['model'] = ['baseline', 'factorization of last dense layer', 'factorization of last two dense layer', 'factorization of last conv layer', 'factorization last conv and two dense layers']\n","display(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"fmGVor5SzOg5","executionInfo":{"status":"ok","timestamp":1679426493168,"user_tz":-60,"elapsed":13,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"4359bc17-ed0d-407a-a81a-cc65fb798164"},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                          model matrix/Tucker rank  \\\n","0                                      baseline                NaN   \n","1             factorization of last dense layer                NaN   \n","2         factorization of last two dense layer                NaN   \n","3              factorization of last conv layer                NaN   \n","4  factorization last conv and two dense layers                NaN   \n","\n","  uncompressed_layer_size compressed_layer_size  \\\n","0                     NaN                   NaN   \n","1                     NaN                   NaN   \n","2                     NaN                   NaN   \n","3                     NaN                   NaN   \n","4                     NaN                   NaN   \n","\n","  compressed_layer_size/uncompressed_layer_size accuracy  \n","0                                           NaN      NaN  \n","1                                           NaN      NaN  \n","2                                           NaN      NaN  \n","3                                           NaN      NaN  \n","4                                           NaN      NaN  "],"text/html":["\n","  <div id=\"df-cb072a37-bc40-4cd8-ba99-28b7fe5b513d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>matrix/Tucker rank</th>\n","      <th>uncompressed_layer_size</th>\n","      <th>compressed_layer_size</th>\n","      <th>compressed_layer_size/uncompressed_layer_size</th>\n","      <th>accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>baseline</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>factorization of last dense layer</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>factorization of last two dense layer</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>factorization of last conv layer</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>factorization last conv and two dense layers</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb072a37-bc40-4cd8-ba99-28b7fe5b513d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cb072a37-bc40-4cd8-ba99-28b7fe5b513d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cb072a37-bc40-4cd8-ba99-28b7fe5b513d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["Data preparation:\n","\n","\n","*   Download [Cifar10](https://keras.io/api/datasets/cifar10/)\n","*   Rescale images between 0 and 1,\n","*   Apply a one-hot encoding to labels of train and test set.\n","\n"],"metadata":{"id":"n_trHBxWkk2k"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QMwhS8nwWDzO","executionInfo":{"status":"ok","timestamp":1679426522178,"user_tz":-60,"elapsed":29020,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"7809dad0-97c9-44c7-aeaa-936dff2df0a3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.utils import to_categorical\n","\n","\n","# Load the CIFAR10 dataset\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","# Rescale images between 0 and 1 (on divise par 255)\n","x_train = x_train.astype('float32') / 255.0\n","x_test = x_test.astype('float32') / 255.0\n","\n","# Apply one-hot encoding to labels\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLDaez5mWASc","executionInfo":{"status":"ok","timestamp":1679444743194,"user_tz":-60,"elapsed":9628,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"d1458127-b7fc-46e5-d194-b3785ba470a8"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 3s 0us/step\n"]}]},{"cell_type":"code","source":["x_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CcBrC-OHh8YD","executionInfo":{"status":"ok","timestamp":1679444747635,"user_tz":-60,"elapsed":10,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"309fed73-8554-496e-8011-435fca2696f4"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 32, 32, 3)"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["# Baseline"],"metadata":{"id":"hKCFmLy-rxEq"}},{"cell_type":"markdown","source":["Below is an implementation of a Dense layer using the Layer class ([here](https://keras.io/guides/making_new_layers_and_models_via_subclassing/) you can find the official Keras doc about custom layers)\n","\n","```\n","class Linear(keras.layers.Layer):\n","    def __init__(self, units, name):\n","        super(Linear, self).__init__()\n","        self.units = units\n","        self._name = name\n","\n","    def build(self, input_shape):\n","        self.w = self.add_weight(\n","            shape=(input_shape[-1], self.units),\n","            initializer=\"random_normal\",\n","            trainable=True)\n","        self.b = self.add_weight(\n","            shape=(self.units,), initializer=\"random_normal\", trainable=True\n","        )\n","\n","    def call(self, inputs):\n","        return tf.matmul(inputs, self.w) + self.b\n","```\n","\n"],"metadata":{"id":"nAPakc6vpFep"}},{"cell_type":"markdown","source":["Baseline implementation:\n","* implement a convolutional Neural Network having 12 convolutional layers with\n","kernel size equal to 3; the number of filters starts from 256 and is divided by 2 every 3 layers; add also MaxPooling layers every 4 convolutional layers; activation function is the ReLU and padding has to be 'same'; \n","* then, after having flattened the output of the last conv layer, add two dense layers having 500 and 10 output neurons respectively. To implement Dense layers, you can leverage the Linear class above, and use it as any regular layer. For instance:\n","\n","```\n","x = MyAwesomeCustomLayer(parameter_1, parameter_2)(x)\n","```\n","* using the parameter 'name', give a name to each layer.\n","\n","\n"],"metadata":{"id":"sQKN9RlQlp7-"}},{"cell_type":"code","source":["import tensorflow as tf\n","import keras\n","\n","class Linear(keras.layers.Layer):\n","    def __init__(self, units, name):\n","        super(Linear, self).__init__()\n","        self.units = units\n","        self._name = name\n","\n","    def build(self, input_shape):\n","        self.w = self.add_weight(\n","            shape=(input_shape[-1], self.units),\n","            initializer=\"random_normal\",\n","            trainable=True)\n","        self.b = self.add_weight(\n","            shape=(self.units,), initializer=\"random_normal\", trainable=True\n","        )\n","\n","    def call(self, inputs):\n","        return tf.matmul(inputs, self.w) + self.b\n","\n","\n","# Define the model architecture\n","model = tf.keras.Sequential([\n","    \n","    # Convolutional layers\n","    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3), name='conv1'),\n","    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='conv2'),\n","    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3'),\n","    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv4'),\n","    tf.keras.layers.MaxPooling2D((2, 2), name='maxpool1'),\n","\n","    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv5'),\n","    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv6'),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv7'),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv8'),\n","    tf.keras.layers.MaxPooling2D((2, 2), name='maxpool2'),\n","\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv9'),\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv10'),\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv11'),\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv12'),\n","    tf.keras.layers.MaxPooling2D((2, 2), name='maxpool4'),\n","    \n","    # Flatten layer\n","    tf.keras.layers.Flatten(name='flatten'),\n","    \n","    # Dense layers\n","    Linear(500, name='dense1'),\n","    Linear(10, name='dense2')\n","])"],"metadata":{"id":"ytrli119WY7O","executionInfo":{"status":"ok","timestamp":1679444752104,"user_tz":-60,"elapsed":4476,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","*   Initialize this (uncompressed) baseline model\n","*   Compile it by choosing a categorical crossentropy loss, Adam optimizer and accuracy metrics,\n","*   train it for 40 epochs with an appropriate [data augmentation](https://keras.io/zh/examples/cifar10_resnet/) strategy; it might be helpful to reduce the learning rate programmatically with the callback   [ReduceLROnPlateau](https://keras.io/api/callbacks/reduce_lr_on_plateau/).\n","\n"],"metadata":{"id":"q4Dqx7jTrENo"}},{"cell_type":"code","source":["from tensorflow.keras.callbacks import ReduceLROnPlateau\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint\n","\n","# Compile the model with categorical crossentropy loss, Adam optimizer, and accuracy metrics\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Define an appropriate data augmentation strategy\n","data_augmentation = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rotation_range=15,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.1,\n","    zoom_range=0.1,\n","    horizontal_flip=True,\n","    fill_mode='nearest')\n","\n","# Define a learning rate reduction callback\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n","\n","# Train the model for 40 epochs with data augmentation and learning rate reduction callback\n","history = model.fit(\n","    data_augmentation.flow(x_train, y_train, batch_size=32),\n","    validation_data=(x_test, y_test),\n","    epochs=4,\n","    callbacks=[reduce_lr])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"21lxM78nd2p9","executionInfo":{"status":"ok","timestamp":1679445461548,"user_tz":-60,"elapsed":301382,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"cccb4cdc-d967-4543-c14f-8f22277addc5"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/4\n","1563/1563 [==============================] - 73s 44ms/step - loss: 6.4472 - accuracy: 0.1000 - val_loss: 6.4472 - val_accuracy: 0.1000 - lr: 0.0010\n","Epoch 2/4\n","1563/1563 [==============================] - 64s 41ms/step - loss: 6.4472 - accuracy: 0.1000 - val_loss: 6.4472 - val_accuracy: 0.1000 - lr: 0.0010\n","Epoch 3/4\n","1563/1563 [==============================] - 64s 41ms/step - loss: 6.4472 - accuracy: 0.1000 - val_loss: 6.4472 - val_accuracy: 0.1000 - lr: 0.0010\n","Epoch 4/4\n","1563/1563 [==============================] - 65s 42ms/step - loss: 6.4472 - accuracy: 0.1000 - val_loss: 6.4472 - val_accuracy: 0.1000 - lr: 0.0010\n"]}]},{"cell_type":"markdown","source":["Before going to the next section, we need to implement a function, called count_layer_weights, that will allow us to count the number of parameters of a given layer for a given model:\n","* this function has 2 parameters: the model and the layer name,\n","* it returns the number of weights for the chosen layer.\n","* to build the function, you might find helpful to check out the two lines of code here below\n","\n","```  \n","for layer in my_model.layers:\n","  print(layer.name, layer.count_params())\n","```\n","\n"],"metadata":{"id":"g5dixPLCu0ls"}},{"cell_type":"code","source":["print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hLAvxPSHtR2v","executionInfo":{"status":"ok","timestamp":1679444922934,"user_tz":-60,"elapsed":428,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"7bfc70c8-dc08-4ab0-cf7b-7e75fe5c3b70"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1 (Conv2D)              (None, 32, 32, 256)       7168      \n","                                                                 \n"," conv2 (Conv2D)              (None, 32, 32, 256)       590080    \n","                                                                 \n"," conv3 (Conv2D)              (None, 32, 32, 256)       590080    \n","                                                                 \n"," conv4 (Conv2D)              (None, 32, 32, 128)       295040    \n","                                                                 \n"," maxpool1 (MaxPooling2D)     (None, 16, 16, 128)       0         \n","                                                                 \n"," conv5 (Conv2D)              (None, 16, 16, 128)       147584    \n","                                                                 \n"," conv6 (Conv2D)              (None, 16, 16, 128)       147584    \n","                                                                 \n"," conv7 (Conv2D)              (None, 16, 16, 64)        73792     \n","                                                                 \n"," conv8 (Conv2D)              (None, 16, 16, 64)        36928     \n","                                                                 \n"," maxpool2 (MaxPooling2D)     (None, 8, 8, 64)          0         \n","                                                                 \n"," conv9 (Conv2D)              (None, 8, 8, 64)          36928     \n","                                                                 \n"," conv10 (Conv2D)             (None, 8, 8, 32)          18464     \n","                                                                 \n"," conv11 (Conv2D)             (None, 8, 8, 32)          9248      \n","                                                                 \n"," conv12 (Conv2D)             (None, 8, 8, 32)          9248      \n","                                                                 \n"," maxpool4 (MaxPooling2D)     (None, 4, 4, 32)          0         \n","                                                                 \n"," flatten (Flatten)           (None, 512)               0         \n","                                                                 \n"," dense1 (Linear)             (None, 500)               256500    \n","                                                                 \n"," dense2 (Linear)             (None, 10)                5010      \n","                                                                 \n","=================================================================\n","Total params: 2,223,654\n","Trainable params: 2,223,654\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["def count_layer_weights(model, layer_name):\n","    for layer in model.layers:\n","        if layer.name == layer_name:\n","            return layer.count_params()\n","    print(f\"Layer with name {layer_name} not found in model\")\n","    return None\n"],"metadata":{"id":"U1Q9Gm4Ngbje","executionInfo":{"status":"ok","timestamp":1679445461550,"user_tz":-60,"elapsed":23,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["count_layer_weights(model,\"conv5\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fJHu6XlgtL6T","executionInfo":{"status":"ok","timestamp":1679445461550,"user_tz":-60,"elapsed":21,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"1d1303e5-c9d8-4212-f3c7-b96bfd7528cd"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["147584"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["model.get_layer('dense2').input_shape\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ySXiDCOb6FP8","executionInfo":{"status":"ok","timestamp":1679445461551,"user_tz":-60,"elapsed":18,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"3e67ee02-9b5b-4faa-f21b-c15b5b30dcee"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(None, 500)"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["model.get_layer('dense1').output_shape\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3cOetyPD6k8f","executionInfo":{"status":"ok","timestamp":1679431481842,"user_tz":-60,"elapsed":288,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"cd85dffb-e0e4-4a5b-d9b5-68ee4bc07af3"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(None, 500)"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["# Factorizing dense layers"],"metadata":{"id":"fuw2qSx2rmJl"}},{"cell_type":"markdown","source":["Taking as an inspiration the Linear class above, implement a MatrixFactorization class.\n","\n","\n","*   a Matrix factorization layer will be characterized by 3 parameters: number of units, matrix rank and layer name\n","*   The operation implemented by this layer is $y = Ax + b= W_1W_2x + b = W_1(W_2x) + b$ where the dimension shared by $W_1$ and $W_2$ is determined by the rank parameter.\n","\n"],"metadata":{"id":"39cJL_fbr91n"}},{"cell_type":"markdown","source":["\n","\n","1.   choose a matrix rank and replace the last dense layer of the baseline with an instance of the MatrixFactorization layer,\n","2.   initialize this model, compile and train it by following the same protocol of the baseline;\n","3. fill the \"results\" dataframe appropriately (you can use the function count_layer_weights to get the compressed and uncompressed layer size),\n","4. repeat from 1. to 3. for a new model where **both** dense layers are factorized. \n","\n","\n","\n"],"metadata":{"id":"9GFmlNFS1GsZ"}},{"cell_type":"markdown","source":[],"metadata":{"id":"SzCmrknw3LuY"}},{"cell_type":"markdown","source":["Below is an implementation of a Dense layer using the Layer class ([here](https://keras.io/guides/making_new_layers_and_models_via_subclassing/) you can find the official Keras doc about custom layers)\n","\n","```\n","class Linear(keras.layers.Layer):\n","    def __init__(self, units, name):\n","        super(Linear, self).__init__()\n","        self.units = units\n","        self._name = name\n","\n","    def build(self, input_shape):\n","        self.w = self.add_weight(\n","            shape=(input_shape[-1], self.units),\n","            initializer=\"random_normal\",\n","            trainable=True)\n","        self.b = self.add_weight(\n","            shape=(self.units,), initializer=\"random_normal\", trainable=True\n","        )\n","\n","    def call(self, inputs):\n","        return tf.matmul(inputs, self.w) + self.b\n","```\n","\n"],"metadata":{"id":"bYxa-Y5H3MCT"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Layer\n","\n","\n","class MatrixFactorization(Layer):\n","    def __init__(self, units, rank, name):\n","        super(MatrixFactorization, self).__init__()\n","        self.units = units\n","        self.rank = rank\n","        self._name = name\n","\n","    def build(self, input_shape):\n","        self.w1 = self.add_weight(\n","            shape=(self.rank, self.units),\n","            initializer=\"random_normal\",\n","            trainable=True)\n","        self.w2 = self.add_weight(\n","            shape=(input_shape[-1], self.rank),\n","            initializer=\"random_normal\",\n","            trainable=True)\n","        self.b = self.add_weight(\n","            shape=(self.units,), initializer=\"random_normal\", trainable=True\n","        )\n","\n","    def call(self, inputs):\n","        x = tf.matmul(inputs, self.w2)\n","        return tf.matmul(x, self.w1) + self.b\n","\n","\n","    \n","\n","        \n"],"metadata":{"id":"ZtoNDsbZkTuJ","executionInfo":{"status":"ok","timestamp":1679445461552,"user_tz":-60,"elapsed":13,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["model1 = tf.keras.Sequential([\n","    \n","    # Convolutional layers\n","    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3), name='conv1'),\n","    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='conv2'),\n","    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3'),\n","    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv4'),\n","    tf.keras.layers.MaxPooling2D((2, 2), name='maxpool1'),\n","\n","    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv5'),\n","    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv6'),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv7'),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv8'),\n","    tf.keras.layers.MaxPooling2D((2, 2), name='maxpool2'),\n","\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv9'),\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv10'),\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv11'),\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv12'),\n","    tf.keras.layers.MaxPooling2D((2, 2), name='maxpool4'),\n","    \n","    # Flatten layer\n","    tf.keras.layers.Flatten(name='flatten'),\n","    \n","    # Dense layers\n","    Linear(500, name='dense1'),\n","    # Matrix Factorization layer\n","    MatrixFactorization(10, 3, name='mf')\n","])\n","\n","# Compile the model with categorical crossentropy loss, Adam optimizer, and accuracy metrics\n","model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Define an appropriate data augmentation strategy\n","data_augmentation = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rotation_range=15,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.1,\n","    zoom_range=0.1,\n","    horizontal_flip=True,\n","    fill_mode='nearest')\n","\n","# Define a learning rate reduction callback\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n","\n","\n","history2 = model1.fit(\n","    data_augmentation.flow(x_train, y_train, batch_size=32),\n","    validation_data=(x_test, y_test),\n","    epochs=4,\n","    callbacks=[reduce_lr])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PMs2KNqfuCNA","executionInfo":{"status":"ok","timestamp":1679445728535,"user_tz":-60,"elapsed":266995,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"68b54ac9-2de6-4087-e65d-a2876e27ef1a"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/4\n","1563/1563 [==============================] - 69s 41ms/step - loss: 9.6349 - accuracy: 0.1000 - val_loss: 9.6709 - val_accuracy: 0.1000 - lr: 0.0010\n","Epoch 2/4\n","1563/1563 [==============================] - 66s 42ms/step - loss: 9.6708 - accuracy: 0.1000 - val_loss: 9.6709 - val_accuracy: 0.1000 - lr: 0.0010\n","Epoch 3/4\n","1563/1563 [==============================] - 63s 40ms/step - loss: 9.6708 - accuracy: 0.1000 - val_loss: 9.6709 - val_accuracy: 0.1000 - lr: 0.0010\n","Epoch 4/4\n","1563/1563 [==============================] - 68s 44ms/step - loss: 9.6708 - accuracy: 0.1000 - val_loss: 9.6709 - val_accuracy: 0.1000 - lr: 0.0010\n"]}]},{"cell_type":"code","source":["print(model1.summary())"],"metadata":{"id":"4Yl80S_Fu8oD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model2 = tf.keras.Sequential([\n","    \n","    # Convolutional layers\n","    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3), name='conv1'),\n","    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='conv2'),\n","    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3'),\n","    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv4'),\n","    tf.keras.layers.MaxPooling2D((2, 2), name='maxpool1'),\n","\n","    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv5'),\n","    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv6'),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv7'),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv8'),\n","    tf.keras.layers.MaxPooling2D((2, 2), name='maxpool2'),\n","\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv9'),\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv10'),\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv11'),\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv12'),\n","    tf.keras.layers.MaxPooling2D((2, 2), name='maxpool4'),\n","    \n","    # Flatten layer\n","    tf.keras.layers.Flatten(name='flatten'),\n","    \n","    # Dense layers\n","    MatrixFactorization(500, 3, name='mf1'),\n","    # Matrix Factorization layer\n","    MatrixFactorization(10, 3, name='mf2')\n","])\n","\n","# Compile the model with categorical crossentropy loss, Adam optimizer, and accuracy metrics\n","model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Define an appropriate data augmentation strategy\n","data_augmentation = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rotation_range=15,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.1,\n","    zoom_range=0.1,\n","    horizontal_flip=True,\n","    fill_mode='nearest')\n","\n","# Define a learning rate reduction callback\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n","\n","\n","history2 = model2.fit(\n","    data_augmentation.flow(x_train, y_train, batch_size=32),\n","    validation_data=(x_test, y_test),\n","    epochs=1,\n","    callbacks=[reduce_lr])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sGZNj8-zBhu1","executionInfo":{"status":"ok","timestamp":1679446839826,"user_tz":-60,"elapsed":79241,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"7e7a3019-c404-404b-e6fe-81db6d1bc3bf"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["1563/1563 [==============================] - 78s 41ms/step - loss: 8.0066 - accuracy: 0.1001 - val_loss: 8.0590 - val_accuracy: 0.1000 - lr: 0.0010\n"]}]},{"cell_type":"markdown","source":["# Factorizing convolutional layers"],"metadata":{"id":"rRa8gJMW2bmy"}},{"cell_type":"markdown","source":["To compress a convolutional layer with Tucker factorization we have to implement a function called conv_tucker_factorization. This function is characterized as follows:\n","\n","\n","*   it has four parameters: the input, the two Tucker ranks, denoted by $R_3$ and $R_4$ and the final number of convolutional filters $T$\n","*   the operation done by this layer can be implemented by stacking three convolutional layer: the first layer is a poitwise convolution with $R_3$ filters; the second one is a 3x3 convolution with $R_4$ filters; the third one is a pointwise convolution with $T$ filters.\n","* do not forget to add non-linearity only after the last convolution. \n","\n"],"metadata":{"id":"6iwYowTp5GUb"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","def conv_tucker_factorization(input_tensor, R3, R4, T):\n","    # Perform pointwise convolution with R3 filters\n","    pointwise_conv1 = tf.keras.layers.Conv2D(R3, (1, 1), padding='same', activation='relu')(input_tensor)\n","\n","    # Perform 3x3 convolution with R4 filters\n","    conv3x3 = tf.keras.layers.Conv2D(R4, (3, 3), padding='same', activation='relu')(pointwise_conv1)\n","\n","    # Perform pointwise convolution with T filters\n","    pointwise_conv2 = tf.keras.layers.Conv2D(T, (1, 1), padding='same', activation='relu')(conv3x3)\n","\n","    # Apply non-linearity after the last convolution\n","    output_tensor = tf.keras.layers.ReLU()(pointwise_conv2)\n","\n","    return output_tensor\n"],"metadata":{"id":"MplQiVTDvYFs","executionInfo":{"status":"ok","timestamp":1679445797708,"user_tz":-60,"elapsed":313,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["Repeat points 2. and 3. described above for a model where the last convolutional has been Tucker-factorized with rank of your choice.\n","\n","\n","Eventually, you can factorize the **both Dense and the convolutional layers**.\n","Copy here below your \"results\" Dataframe filled with the results you obtained."],"metadata":{"id":"A_ntAqF-9BDu"}},{"cell_type":"code","source":["\n","def ConvTucker2D(R3, R4, T):\n","    def conv_tucker_factorization(input_tensor):\n","        # Perform pointwise convolution with R3 filters\n","        pointwise_conv1 = tf.keras.layers.Conv2D(R3, (1, 1), padding='same', activation='relu')(input_tensor)\n","\n","        # Perform 3x3 convolution with R4 filters\n","        conv3x3 = tf.keras.layers.Conv2D(R4, (3, 3), padding='same', activation='relu')(pointwise_conv1)\n","\n","        # Perform pointwise convolution with T filters\n","        pointwise_conv2 = tf.keras.layers.Conv2D(T, (1, 1), padding='same', activation='relu')(conv3x3)\n","\n","        # Apply non-linearity after the last convolution\n","        output_tensor = tf.keras.layers.ReLU()(pointwise_conv2)\n","\n","        return output_tensor\n","    \n","    return tf.keras.layers.Lambda(conv_tucker_factorization)\n"],"metadata":{"id":"ocIbDalX1nRz","executionInfo":{"status":"ok","timestamp":1679448042567,"user_tz":-60,"elapsed":338,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["R3 = 2\n","R4 = 3\n","T = 4\n","\n","# Split model2 into two parts: the first convolutional layer and the rest of the model\n","first_conv_layer = model2.get_layer('conv1')\n","rest_of_model = tf.keras.Sequential(model2.layers[1:])\n","\n","# Apply conv_tucker_factorization to the first convolutional layer\n","new_first_conv_layer = ConvTucker2D(R3=R3, R4=R4, T=T)(first_conv_layer)\n","# Combine the modified first convolutional layer with the rest of the model\n","new_model2 = tf.keras.Sequential([\n","    new_first_conv_layer,\n","    rest_of_model\n","])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"ZbZJAqW_v7b6","executionInfo":{"status":"error","timestamp":1679448046101,"user_tz":-60,"elapsed":424,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"0d9d5eaa-bf19-4144-ba75-fa4bf3304f75"},"execution_count":50,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-379189363f6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Combine the modified first convolutional layer with the rest of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m new_model2 = tf.keras.Sequential([\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mnew_first_conv_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mrest_of_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0;34m\"The added layer must be an instance of class Layer. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;34mf\"Received: layer={layer} of type {type(layer)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Received: layer=KerasTensor(type_spec=TensorSpec(shape=(None, 32, 32, 4), dtype=tf.float32, name=None), name='re_lu_11/Relu:0', description=\"created by layer 're_lu_11'\") of type <class 'keras.engine.keras_tensor.KerasTensor'>."]}]}]}