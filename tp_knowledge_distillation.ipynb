{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3780,"status":"ok","timestamp":1678797882733,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"},"user_tz":-60},"id":"zcXn3JeyPuni","outputId":"ed601c9e-66d3-4744-8cf3-88b90492b434"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"YI6a4-0Uwagi"},"source":["* Rename this notebook as PRENOM_NOM_TP_DISTILLATION.ipynb\n","* Delivery deadline is March the 14th\n"]},{"cell_type":"markdown","metadata":{"id":"Y9zptINQAhOe"},"source":["**Fact that wil be helpful for the exercise**. Given a Neural Network architecture\n","\n","```\n","inputs = Input(shape=input_shape)\n","y = Conv2D(filters=64, kernel_size=kernel_size, activation='relu', padding='same')(inputs)\n","y = Conv2D(filters=64, kernel_size=kernel_size, activation='relu', padding='same')(y)\n","y = MaxPooling2D()(y)\n","y = Conv2D(filters=32, kernel_size=kernel_size, activation='relu', padding='same')(y)\n","output_1 = Conv2D(filters=32, kernel_size=kernel_size, activation='relu', padding='same')(y)\n","y = MaxPooling2D()(output_1)\n","y = Conv2D(filters=32, kernel_size=kernel_size, activation='relu', padding='same')(y)\n","y = Flatten()(y)\n","y = Dense(10)(y)\n","output_2 = Activation('softmax')(y)\n","```\n","We can define two different models by specifying input and output. For instance\n","\n","\n","```\n","model_1 = Model(inputs=inputs, outputs=output_1)\n","model_2 = Model(inputs=inputs, outputs=output_2)\n","```\n","Moreover, if we compile both models and, say, we train model_1, then the weights of model_2 that are shared with model_1 will be learned too.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5AL9w7mOwyEp"},"source":["# Data preparation\n","1. Download the [CIFAR10 dataset](https://keras.io/api/datasets/cifar10/).\n","2. Rescale images between 0 and 1.\n","3. Apply a one-hot encoding to labels of both train and test dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x0my5UdQSthN"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.utils import to_categorical\n","\n","\n","# Load the CIFAR10 dataset\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","# Rescale images between 0 and 1 (on divise par 255)\n","x_train = x_train.astype('float32') / 255.0\n","x_test = x_test.astype('float32') / 255.0\n","\n","# Apply one-hot encoding to labels\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1055,"status":"ok","timestamp":1678797914183,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"},"user_tz":-60},"id":"bTvkjsmAWNP-","outputId":"16f0c471-a183-4c5f-b12f-41fca1966d02"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 32, 32, 3)"]},"metadata":{},"execution_count":3}],"source":["x_train.shape"]},{"cell_type":"markdown","metadata":{"id":"I6vUa0zPFNHz"},"source":["[texte du lien](https://)# Hinton distillation"]},{"cell_type":"markdown","metadata":{"id":"6JNMrRCb2TFA"},"source":["Define the Teacher Neural Network: this has 16 convolutional layers built with the [Keras functional API](https://keras.io/guides/functional_api/), with kernel size equal to 3; the number of filters starts from 256 and is divided by 2 every 4 layers; add also MaxPooling layers every 4 convolutional layers. Activation function is the ReLU and padding has to be 'same'.\n","the Teacher Net architecture has **two outputs** that bifurcate right after the last dense layer: \n","1. the 'normal' output is made of a Softmax activation;\n","2. the 'heated' output is made of a [Lambda layer](https://keras.io/api/layers/core_layers/lambda/) + a Softmax activation. The parameter $\\tau$ (the temperature) can be chosen in the interval (1, 10)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TH-rIA07VMrl"},"outputs":[],"source":["# from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\n","# from tensorflow.keras.models import Model\n","# import tensorflow.keras.backend as K\n","\n","# # Define input shape\n","# input_shape = (32, 32, 3)\n","\n","# # Define temperature\n","# tau = 1\n","\n","# # Define input layer\n","# inputs = Input(shape=input_shape)\n","\n","# # Initialize number of filters\n","# num_filters = 256\n","\n","# # Add 16 convolutional layers with decreasing number of filters\n","\n","# x = Conv2D(num_filters, (3, 3), padding='same', activation='relu')(inputs)\n","\n","# for i in range(1,16):\n","#     x = Conv2D(num_filters, (3, 3), padding='same', activation='relu')(x)\n","#     # Add MaxPooling every 4 convolutional layers\n","#     if (i+1) % 4 == 0:\n","#         x = MaxPooling2D((2, 2))(x)\n","        \n","#     # Decrease number of filters every 4 convolutional layers\n","#     if (i+1) % 4 == 0 and i != 15:\n","#         num_filters = num_filters/2\n","        \n","# # Flatten output of last convolutional layer\n","# x = Flatten()(x)\n","\n","# # Add dense layer\n","# x = Dense(256, activation='relu')(x)\n","\n","# # Define normal output with Softmax activation\n","# normal_output = Dense(10, activation='softmax', name='normal_output')(x)\n","\n","# # Define heated output with Lambda layer and Softmax activation\n","# heated_output = Lambda(lambda x: x / tau)(x)\n","# heated_output = Dense(10, activation='softmax', name='heated_output')(heated_output)\n","\n","# # Define Teacher Net model\n","# teacher = Model(inputs=inputs, outputs=[normal_output, heated_output])\n","\n","\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda, Activation\n","from tensorflow.keras.models import Model\n","import tensorflow.keras.backend as K\n","\n","def define_teacher_net(input_shape, tau):\n","    # Define input layer\n","    inputs = Input(shape=input_shape)\n","\n","    # Initialize number of filters\n","    num_filters = 256\n","\n","    # Add 16 convolutional layers with decreasing number of filters\n","    x = Conv2D(num_filters, (3, 3), padding='same', activation='relu')(inputs)\n","\n","    for i in range(1, 16):\n","        x = Conv2D(num_filters, (3, 3), padding='same', activation='relu')(x)\n","        # Add MaxPooling every 4 convolutional layers\n","        if (i+1) % 3 == 0 and i != 15:\n","            x = MaxPooling2D((2, 2))(x)\n","\n","        # Decrease number of filters every 4 convolutional layers\n","        if (i+1) % 3 == 0 and i != 15:\n","            num_filters = num_filters / 2\n","\n","    # Flatten output of last convolutional layer\n","    x = Flatten()(x)\n","\n","    # Add dense layer\n","    x = Dense(256, activation='relu')(x)\n","\n","    # Define normal output with Softmax activation\n","    normal_output = Dense(10, activation='softmax', name='normal_teacher')(x)\n","\n","    # Define heated output with Lambda layer and Softmax activation\n","\n","    #On teste et on remet ces 2 lignes\n","    #heated_output = Lambda(lambda x: x / tau)(x)\n","    #heated_output = Dense(10, activation='softmax', name='heated_teacher')(heated_output)\n","\n","    #heated_output = Dense(10, name='heated_teacher')(x)\n","    #Ca je l'ai ajouté\n","    heated_output = Dense(10, name='heated_teacher')(x)\n","    heated_output = Lambda(lambda x: K.softmax(x / tau))(heated_output)\n","\n","\n","    # Define Teacher Net model\n","    teacher = Model(inputs=inputs, outputs=[normal_output, heated_output], name='Teacher_Net')\n","    \n","    return teacher\n","\n","\n","def compile_teacher_net(teacher):\n","    # Compile Teacher Net model\n","    teacher.compile(loss=['categorical_crossentropy','categorical_crossentropy'],\n","                    optimizer='adam',\n","                    metrics=['accuracy'])\n","    \n","    return teacher\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RC4olWgmaR1s"},"outputs":[],"source":["# Define input shape\n","input_shape = (32, 32, 3)\n","\n","# Define temperature\n","tau = 1\n","\n","# Define Teacher Net model\n","teacher = define_teacher_net(input_shape, tau)\n","\n","# Compile Teacher Net model\n","teacher = compile_teacher_net(teacher)"]},{"cell_type":"code","source":["print(teacher.summary())"],"metadata":{"id":"Oagtn97pGLvm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yph29hVj5f2k"},"source":["\\Initialize both models with the 'normal' output and the 'heated' output, by \n","\n","---\n","\n","naming them respectively normal_teacher and heated_teacher.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B6hRutQSeLkB"},"outputs":[],"source":["#len(teacher.get_weights())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8TdanK9cbw1r"},"outputs":[],"source":["import keras\n","# Create new model for normal output using pre-trained weights of Teacher Net\n","normal_teacher = Model(inputs=teacher.input, outputs=teacher.get_layer('normal_teacher').output, name='normal_teacher')\n","\n","# Create new model for heated output using pre-trained weights of Teacher Net\n","heated_teacher = Model(inputs=teacher.input, outputs=teacher.get_layer('heated_teacher').output, name='heated_teacher')\n","\n","# Clone student for later comparison\n","normal_teacher_scratch = keras.models.clone_model(normal_teacher)\n","\n","# Print summary of normal_teacher and heated_teacher models\n","print(\"Summary of normal_teacher:\")\n","print(normal_teacher.summary())\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OQhOZYEeEtZc"},"outputs":[],"source":["#Summary of heated teacher\n","print(\"Summary of heated_teacher:\")\n","print(heated_teacher.summary())"]},{"cell_type":"markdown","metadata":{"id":"LdW4Ofkp6WVq"},"source":["Compile **both** normal_teacher and heated_teacher by choosing a categorical crossentropy loss, Adam optimizer and accuracy metrics."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SHIIi7a8hDxo"},"outputs":[],"source":["def compile_normal(normal_teacher):\n","    # Compile Teacher Net model\n","    normal_teacher.compile(loss=['categorical_crossentropy'],\n","                    optimizer='adam',\n","                    metrics=['accuracy'])\n","    \n","    return normal_teacher\n","\n","def compile_heated(heated_teacher):\n","    # Compile Teacher Net model\n","    heated_teacher.compile(loss=['categorical_crossentropy'],\n","                    optimizer='adam',\n","                    metrics=['accuracy'])\n","    \n","    return heated_teacher\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KmZ1nYAriu8Q"},"outputs":[],"source":["# Compile normal_Teacher Net model\n","normal_teacher = compile_normal(normal_teacher)\n","heated_teacher = compile_heated(heated_teacher)"]},{"cell_type":"markdown","metadata":{"id":"aFhVNn0p91Dn"},"source":["Train the Teacher Net with normal output using an appropriate [data augmentation](https://keras.io/zh/examples/cifar10_resnet/) strategy; it might be helpful to reduce the learning rate programmatically with the callback   [ReduceLROnPlateau](https://keras.io/api/callbacks/reduce_lr_on_plateau/). Write few lines to comment the choice you made.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":456811,"status":"ok","timestamp":1678798531859,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"},"user_tz":-60},"id":"F__Dwc0yjOGV","outputId":"a121575d-5f41-4169-af1b-a70221f0d607"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/8\n","391/391 [==============================] - 67s 141ms/step - loss: 4.6053 - normal_teacher_loss: 2.3026 - lambda_1_loss: 2.3027 - normal_teacher_accuracy: 0.0994 - lambda_1_accuracy: 0.0967 - val_loss: 4.6052 - val_normal_teacher_loss: 2.3026 - val_lambda_1_loss: 2.3026 - val_normal_teacher_accuracy: 0.1000 - val_lambda_1_accuracy: 0.1000 - lr: 0.0010\n","Epoch 2/8\n","391/391 [==============================] - 52s 132ms/step - loss: 4.6054 - normal_teacher_loss: 2.3027 - lambda_1_loss: 2.3027 - normal_teacher_accuracy: 0.0982 - lambda_1_accuracy: 0.0987 - val_loss: 4.6052 - val_normal_teacher_loss: 2.3026 - val_lambda_1_loss: 2.3026 - val_normal_teacher_accuracy: 0.1000 - val_lambda_1_accuracy: 0.1000 - lr: 0.0010\n","Epoch 3/8\n","391/391 [==============================] - 52s 131ms/step - loss: 4.6054 - normal_teacher_loss: 2.3027 - lambda_1_loss: 2.3027 - normal_teacher_accuracy: 0.0991 - lambda_1_accuracy: 0.0978 - val_loss: 4.6052 - val_normal_teacher_loss: 2.3026 - val_lambda_1_loss: 2.3026 - val_normal_teacher_accuracy: 0.1000 - val_lambda_1_accuracy: 0.1000 - lr: 0.0010\n","Epoch 4/8\n","391/391 [==============================] - ETA: 0s - loss: 4.6054 - normal_teacher_loss: 2.3027 - lambda_1_loss: 2.3027 - normal_teacher_accuracy: 0.0992 - lambda_1_accuracy: 0.0990\n","Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","391/391 [==============================] - 51s 129ms/step - loss: 4.6054 - normal_teacher_loss: 2.3027 - lambda_1_loss: 2.3027 - normal_teacher_accuracy: 0.0992 - lambda_1_accuracy: 0.0990 - val_loss: 4.6052 - val_normal_teacher_loss: 2.3026 - val_lambda_1_loss: 2.3026 - val_normal_teacher_accuracy: 0.1000 - val_lambda_1_accuracy: 0.1000 - lr: 0.0010\n","Epoch 5/8\n","391/391 [==============================] - 50s 126ms/step - loss: 4.6053 - normal_teacher_loss: 2.3026 - lambda_1_loss: 2.3026 - normal_teacher_accuracy: 0.0986 - lambda_1_accuracy: 0.0987 - val_loss: 4.6052 - val_normal_teacher_loss: 2.3026 - val_lambda_1_loss: 2.3026 - val_normal_teacher_accuracy: 0.1000 - val_lambda_1_accuracy: 0.1000 - lr: 5.0000e-04\n","Epoch 6/8\n","391/391 [==============================] - 50s 127ms/step - loss: 4.6053 - normal_teacher_loss: 2.3026 - lambda_1_loss: 2.3026 - normal_teacher_accuracy: 0.0973 - lambda_1_accuracy: 0.0978 - val_loss: 4.6052 - val_normal_teacher_loss: 2.3026 - val_lambda_1_loss: 2.3026 - val_normal_teacher_accuracy: 0.1000 - val_lambda_1_accuracy: 0.1000 - lr: 5.0000e-04\n","Epoch 7/8\n","391/391 [==============================] - ETA: 0s - loss: 4.6053 - normal_teacher_loss: 2.3026 - lambda_1_loss: 2.3026 - normal_teacher_accuracy: 0.0973 - lambda_1_accuracy: 0.0973\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","391/391 [==============================] - 52s 131ms/step - loss: 4.6053 - normal_teacher_loss: 2.3026 - lambda_1_loss: 2.3026 - normal_teacher_accuracy: 0.0973 - lambda_1_accuracy: 0.0973 - val_loss: 4.6052 - val_normal_teacher_loss: 2.3026 - val_lambda_1_loss: 2.3026 - val_normal_teacher_accuracy: 0.1000 - val_lambda_1_accuracy: 0.1000 - lr: 5.0000e-04\n","Epoch 8/8\n","391/391 [==============================] - 50s 127ms/step - loss: 4.6052 - normal_teacher_loss: 2.3026 - lambda_1_loss: 2.3026 - normal_teacher_accuracy: 0.0959 - lambda_1_accuracy: 0.0963 - val_loss: 4.6052 - val_normal_teacher_loss: 2.3026 - val_lambda_1_loss: 2.3026 - val_normal_teacher_accuracy: 0.1000 - val_lambda_1_accuracy: 0.1000 - lr: 2.5000e-04\n"]}],"source":["from tensorflow.keras.callbacks import ReduceLROnPlateau\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint\n","\n","batch_size = 128\n","epochs = 8\n","\n","datagen = ImageDataGenerator(\n","    featurewise_center=False,  # set input mean to 0 over the dataset\n","    samplewise_center=False,  # set each sample mean to 0\n","    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","    samplewise_std_normalization=False,  # divide each input by its std\n","    zca_whitening=False,  # apply ZCA whitening\n","    zca_epsilon=1e-06,  # epsilon for ZCA whitening\n","    rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n","    # randomly shift images horizontally (fraction of total width)\n","    width_shift_range=0.1,\n","    # randomly shift images vertically (fraction of total height)\n","    height_shift_range=0.1,\n","    shear_range=0.1,  # set range for random shear\n","    zoom_range=0.2,  # set range for random zoom\n","    channel_shift_range=0.,  # set range for random channel shifts\n","    # set mode for filling points outside the input boundaries\n","    fill_mode='nearest',\n","    cval=0.,  # value used for fill_mode = \"constant\"\n","    horizontal_flip=True,  # randomly flip images\n","    vertical_flip=False,  # randomly flip images\n","    # set rescaling factor (applied before any other transformation)\n","    rescale=None,\n","    # set function that will be applied on each input\n","    preprocessing_function=None,\n","    # image data format, either \"channels_first\" or \"channels_last\"\n","    data_format=None)\n","\n","\n","datagen.fit(x_train)\n","\n","\n","# Train Teacher Net model with normal output\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=0.00001)\n","\n","# history = teacher.fit(train_datagen.flow(x_train, [y_train, y_train], batch_size=batch_size),\n","#                       steps_per_epoch=len(x_train) / batch_size, epochs=epochs,\n","#                       validation_data=(x_val, [y_val, y_val]), callbacks=[reduce_lr])\n","\n","\n","\n","history1 = teacher.fit(datagen.flow(x_train, y_train,\n","                                 batch_size=batch_size),\n","                    epochs=epochs,\n","                    validation_data=(x_test, y_test),\n","                    workers=4, callbacks=[reduce_lr])\n","\n"]},{"cell_type":"markdown","metadata":{"id":"j6pdPZ5Z-MaD"},"source":["To obtain y_train_heated and y_test_heated, simply \n","\n","1.   Élément de liste\n","2.   Élément de liste\n","\n","run a predict of the heated_teacher on x_train and x_test."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28567,"status":"ok","timestamp":1678798573614,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"},"user_tz":-60},"id":"AMUfB2BIoQqy","outputId":"7c3ed319-429f-4889-d5de-d9f919ed4cb9"},"outputs":[{"output_type":"stream","name":"stdout","text":["1563/1563 [==============================] - 15s 9ms/step\n","313/313 [==============================] - 3s 10ms/step\n"]}],"source":["y_train_heated = heated_teacher.predict(x_train)\n","y_test_heated = heated_teacher.predict(x_test)\n"]},{"cell_type":"markdown","metadata":{"id":"_h-DHqit_DBY"},"source":["The Student architecture we will be using, much smaller than the Teacher, can be found here below:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T-Qh6u59_O0X"},"outputs":[],"source":["kernel_size = (3, 3)\n","inputs = Input(shape=input_shape)\n","y = Conv2D(filters=64, kernel_size=kernel_size, activation='relu', padding='same')(inputs)\n","y = Conv2D(filters=64, kernel_size=kernel_size, activation='relu', padding='same')(y)\n","y = MaxPooling2D()(y)\n","y = Conv2D(filters=32, kernel_size=kernel_size, activation='relu', padding='same')(y)\n","y = Conv2D(filters=32, kernel_size=kernel_size, activation='relu', padding='same')(y)\n","y = MaxPooling2D()(y)\n","y = Conv2D(filters=32, kernel_size=kernel_size, activation='relu', padding='same')(y)\n","y = Flatten()(y)\n","y = Dense(10)(y)\n","normal_output = Activation('softmax', name=\"normal_output\")(y)"]},{"cell_type":"markdown","metadata":{"id":"9ybxDK0u_ZUE"},"source":["First of all, we want to asses the performance of this base Student model with no guidance. For this you should \n","1. initialize the model (you can name it base_student), \n","2. compile it with categorical crossentropy loss, Adam optimizer, accuracy metric,\n","3. train it for 25 epochs with no data augmentation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qx6rIrK7SpW-"},"outputs":[],"source":["base_student = Model(inputs=inputs, outputs=normal_output)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"spwPjQ5TTKpq"},"outputs":[],"source":["base_student.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":152383,"status":"ok","timestamp":1678798767177,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"},"user_tz":-60},"id":"zUUPoi2XSyXf","outputId":"a542125b-2e6d-4665-b74b-844946bd6301"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","391/391 [==============================] - 9s 18ms/step - loss: 1.6270 - accuracy: 0.4113 - val_loss: 1.3498 - val_accuracy: 0.5129\n","Epoch 2/25\n","391/391 [==============================] - 6s 15ms/step - loss: 1.2115 - accuracy: 0.5674 - val_loss: 1.1655 - val_accuracy: 0.5926\n","Epoch 3/25\n","391/391 [==============================] - 6s 15ms/step - loss: 1.0231 - accuracy: 0.6393 - val_loss: 0.9538 - val_accuracy: 0.6669\n","Epoch 4/25\n","391/391 [==============================] - 6s 15ms/step - loss: 0.8790 - accuracy: 0.6912 - val_loss: 0.8887 - val_accuracy: 0.6909\n","Epoch 5/25\n","391/391 [==============================] - 6s 15ms/step - loss: 0.7897 - accuracy: 0.7254 - val_loss: 0.8202 - val_accuracy: 0.7185\n","Epoch 6/25\n","391/391 [==============================] - 6s 15ms/step - loss: 0.7177 - accuracy: 0.7487 - val_loss: 0.8130 - val_accuracy: 0.7176\n","Epoch 7/25\n","391/391 [==============================] - 6s 14ms/step - loss: 0.6644 - accuracy: 0.7692 - val_loss: 0.7837 - val_accuracy: 0.7307\n","Epoch 8/25\n","391/391 [==============================] - 6s 15ms/step - loss: 0.6244 - accuracy: 0.7846 - val_loss: 0.7597 - val_accuracy: 0.7405\n","Epoch 9/25\n","391/391 [==============================] - 6s 14ms/step - loss: 0.5811 - accuracy: 0.7981 - val_loss: 0.7865 - val_accuracy: 0.7255\n","Epoch 10/25\n","391/391 [==============================] - 6s 15ms/step - loss: 0.5451 - accuracy: 0.8105 - val_loss: 0.8036 - val_accuracy: 0.7374\n","Epoch 11/25\n","391/391 [==============================] - 6s 16ms/step - loss: 0.5171 - accuracy: 0.8181 - val_loss: 0.7745 - val_accuracy: 0.7457\n","Epoch 12/25\n","391/391 [==============================] - 6s 14ms/step - loss: 0.4923 - accuracy: 0.8295 - val_loss: 0.7793 - val_accuracy: 0.7461\n","Epoch 13/25\n","391/391 [==============================] - 6s 15ms/step - loss: 0.4599 - accuracy: 0.8395 - val_loss: 0.8130 - val_accuracy: 0.7327\n","Epoch 14/25\n","391/391 [==============================] - 6s 15ms/step - loss: 0.4446 - accuracy: 0.8430 - val_loss: 0.8019 - val_accuracy: 0.7411\n","Epoch 15/25\n","391/391 [==============================] - 6s 16ms/step - loss: 0.4130 - accuracy: 0.8546 - val_loss: 0.8039 - val_accuracy: 0.7414\n","Epoch 16/25\n","391/391 [==============================] - 6s 15ms/step - loss: 0.3916 - accuracy: 0.8621 - val_loss: 0.8378 - val_accuracy: 0.7418\n","Epoch 17/25\n","391/391 [==============================] - 6s 15ms/step - loss: 0.3758 - accuracy: 0.8668 - val_loss: 0.8585 - val_accuracy: 0.7428\n","Epoch 18/25\n","391/391 [==============================] - 6s 15ms/step - loss: 0.3512 - accuracy: 0.8756 - val_loss: 0.8864 - val_accuracy: 0.7345\n","Epoch 19/25\n","391/391 [==============================] - 6s 15ms/step - loss: 0.3367 - accuracy: 0.8816 - val_loss: 0.9235 - val_accuracy: 0.7362\n","Epoch 20/25\n","391/391 [==============================] - 6s 15ms/step - loss: 0.3169 - accuracy: 0.8865 - val_loss: 0.9440 - val_accuracy: 0.7385\n","Epoch 21/25\n","391/391 [==============================] - 6s 15ms/step - loss: 0.2986 - accuracy: 0.8932 - val_loss: 0.9322 - val_accuracy: 0.7393\n","Epoch 22/25\n","391/391 [==============================] - 6s 15ms/step - loss: 0.2832 - accuracy: 0.8984 - val_loss: 1.0084 - val_accuracy: 0.7365\n","Epoch 23/25\n","391/391 [==============================] - 6s 15ms/step - loss: 0.2657 - accuracy: 0.9052 - val_loss: 1.0451 - val_accuracy: 0.7366\n","Epoch 24/25\n","391/391 [==============================] - 6s 16ms/step - loss: 0.2536 - accuracy: 0.9088 - val_loss: 1.1458 - val_accuracy: 0.7280\n","Epoch 25/25\n","391/391 [==============================] - 6s 15ms/step - loss: 0.2434 - accuracy: 0.9127 - val_loss: 1.1439 - val_accuracy: 0.7238\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f4a97f9f6a0>"]},"metadata":{},"execution_count":24}],"source":["base_student.fit(x_train, y_train, batch_size=128, epochs=25, validation_data=(x_test, y_test))\n"]},{"cell_type":"markdown","metadata":{"id":"NpqoAmlMAenG"},"source":["As you did with the Teacher Net, you should add a heated output to the Student Net, made of a Lambda layer + Softmax activation. This new student_distilled model has two outputs (normal and heated) and can be trained with x_train and supervised with both y_train and y_train_heated. [Here](https://stackoverflow.com/questions/44036971/multiple-outputs-in-keras) you can find how to initialize a Keras model with multiple outputs. In our case both outputs require a categorical crossentropy and accuracy metric."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fK__gdxuU2QY"},"outputs":[],"source":["temperature = 5.0\n","\n","heated_logits = Lambda(lambda x: x / temperature)(y)\n","\n","heated_output = Activation('softmax', name=\"heated_output\")(heated_logits)\n","\n","\n","student_distilled = Model(inputs=inputs, outputs=[normal_output, heated_output])\n"]},{"cell_type":"markdown","metadata":{"id":"BzedUvdiDVI7"},"source":["You can now train the two-outputs student_distilled model that leverages the Teacher heated output. To do this, you have to\n","1. choose a categorical crossentropy loss, Adam optimizer and accuracy metric for both outputs,\n","2. train it for 25 epochs with no data augmentation."]},{"cell_type":"markdown","metadata":{"id":"xckPWwQyWHgZ"},"source":["You can choose the temperature parameter τ such that  3 < τ < 8.\n","\n","---\n","\n","\n","Comment the results. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":145320,"status":"ok","timestamp":1678798954062,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"},"user_tz":-60},"id":"sMoYhL_7d6AO","outputId":"a42c9a77-ef47-45e5-b975-dcb2272f6c8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/16\n","391/391 [==============================] - 7s 17ms/step - loss: 5658838016.0000 - normal_output_loss: 5673001472.0000 - heated_output_loss: -14162108.0000 - normal_output_accuracy: 0.1675 - heated_output_accuracy: 0.0927 - val_loss: 56662671360.0000 - val_normal_output_loss: 56811466752.0000 - val_heated_output_loss: -148805312.0000 - val_normal_output_accuracy: 0.1468 - val_heated_output_accuracy: 0.4552\n","Epoch 2/16\n","391/391 [==============================] - 6s 16ms/step - loss: 901988155392.0000 - normal_output_loss: 904303738880.0000 - heated_output_loss: -2315351040.0000 - normal_output_accuracy: 0.1274 - heated_output_accuracy: 0.0937 - val_loss: 2613990129664.0000 - val_normal_output_loss: 2619891515392.0000 - val_heated_output_loss: -5901368320.0000 - val_normal_output_accuracy: 0.1055 - val_heated_output_accuracy: 0.9634\n","Epoch 3/16\n","391/391 [==============================] - 6s 16ms/step - loss: 12917098414080.0000 - normal_output_loss: 12951654236160.0000 - heated_output_loss: -34551095296.0000 - normal_output_accuracy: 0.1326 - heated_output_accuracy: 0.0953 - val_loss: 57333833007104.0000 - val_normal_output_loss: 57474518351872.0000 - val_heated_output_loss: -140685737984.0000 - val_normal_output_accuracy: 0.0989 - val_heated_output_accuracy: 0.0000e+00\n","Epoch 4/16\n","391/391 [==============================] - 6s 16ms/step - loss: 65181593894912.0000 - normal_output_loss: 65345377271808.0000 - heated_output_loss: -163839819776.0000 - normal_output_accuracy: 0.1355 - heated_output_accuracy: 0.0954 - val_loss: 123792567304192.0000 - val_normal_output_loss: 124248219713536.0000 - val_heated_output_loss: -455644446720.0000 - val_normal_output_accuracy: 0.1147 - val_heated_output_accuracy: 0.0069\n","Epoch 5/16\n","391/391 [==============================] - 6s 16ms/step - loss: 190789409832960.0000 - normal_output_loss: 191272929198080.0000 - heated_output_loss: -483660398592.0000 - normal_output_accuracy: 0.1297 - heated_output_accuracy: 0.0931 - val_loss: 306387968065536.0000 - val_normal_output_loss: 307442952962048.0000 - val_heated_output_loss: -1055032606720.0000 - val_normal_output_accuracy: 0.1246 - val_heated_output_accuracy: 0.7542\n","Epoch 6/16\n","391/391 [==============================] - 6s 15ms/step - loss: 452749917421568.0000 - normal_output_loss: 453963816108032.0000 - heated_output_loss: -1213606789120.0000 - normal_output_accuracy: 0.1333 - heated_output_accuracy: 0.0946 - val_loss: 659898706690048.0000 - val_normal_output_loss: 661906603900928.0000 - val_heated_output_loss: -2008024350720.0000 - val_normal_output_accuracy: 0.1617 - val_heated_output_accuracy: 0.6900\n","Epoch 7/16\n","391/391 [==============================] - 6s 16ms/step - loss: 868808466104320.0000 - normal_output_loss: 871027219365888.0000 - heated_output_loss: -2218607509504.0000 - normal_output_accuracy: 0.1348 - heated_output_accuracy: 0.0966 - val_loss: 912130190606336.0000 - val_normal_output_loss: 913922802581504.0000 - val_heated_output_loss: -1792561512448.0000 - val_normal_output_accuracy: 0.1537 - val_heated_output_accuracy: 0.0000e+00\n","Epoch 8/16\n","391/391 [==============================] - 6s 15ms/step - loss: 1529424566550528.0000 - normal_output_loss: 1533343858425856.0000 - heated_output_loss: -3919054110720.0000 - normal_output_accuracy: 0.1341 - heated_output_accuracy: 0.0954 - val_loss: 2143150965522432.0000 - val_normal_output_loss: 2147403654234112.0000 - val_heated_output_loss: -4252307030016.0000 - val_normal_output_accuracy: 0.1029 - val_heated_output_accuracy: 0.0000e+00\n","Epoch 9/16\n","391/391 [==============================] - 6s 16ms/step - loss: 2498561254096896.0000 - normal_output_loss: 2504950017949696.0000 - heated_output_loss: -6388754939904.0000 - normal_output_accuracy: 0.1336 - heated_output_accuracy: 0.0933 - val_loss: 1720635705262080.0000 - val_normal_output_loss: 1727859169165312.0000 - val_heated_output_loss: -7223667851264.0000 - val_normal_output_accuracy: 0.1400 - val_heated_output_accuracy: 0.0071\n","Epoch 10/16\n","391/391 [==============================] - 6s 15ms/step - loss: 3445569062174720.0000 - normal_output_loss: 3454456423251968.0000 - heated_output_loss: -8889704644608.0000 - normal_output_accuracy: 0.1403 - heated_output_accuracy: 0.0952 - val_loss: 2945217183350784.0000 - val_normal_output_loss: 2956493083115520.0000 - val_heated_output_loss: -11275043078144.0000 - val_normal_output_accuracy: 0.1449 - val_heated_output_accuracy: 0.1061\n","Epoch 11/16\n","391/391 [==============================] - 6s 17ms/step - loss: 5625080549736448.0000 - normal_output_loss: 5639770411630592.0000 - heated_output_loss: -14692404690944.0000 - normal_output_accuracy: 0.1331 - heated_output_accuracy: 0.0947 - val_loss: 9234505030172672.0000 - val_normal_output_loss: 9257777310466048.0000 - val_heated_output_loss: -23270885687296.0000 - val_normal_output_accuracy: 0.1105 - val_heated_output_accuracy: 0.0000e+00\n","Epoch 12/16\n","391/391 [==============================] - 6s 15ms/step - loss: 7807211162042368.0000 - normal_output_loss: 7827342210629632.0000 - heated_output_loss: -20127577800704.0000 - normal_output_accuracy: 0.1343 - heated_output_accuracy: 0.0949 - val_loss: 7769921719107584.0000 - val_normal_output_loss: 7784491321917440.0000 - val_heated_output_loss: -14571322474496.0000 - val_normal_output_accuracy: 0.1245 - val_heated_output_accuracy: 0.0000e+00\n","Epoch 13/16\n","391/391 [==============================] - 6s 16ms/step - loss: 9998761174499328.0000 - normal_output_loss: 10024241067982848.0000 - heated_output_loss: -25482496049152.0000 - normal_output_accuracy: 0.1379 - heated_output_accuracy: 0.0938 - val_loss: 17703769294766080.0000 - val_normal_output_loss: 17746017814315008.0000 - val_heated_output_loss: -42247399669760.0000 - val_normal_output_accuracy: 0.1035 - val_heated_output_accuracy: 0.0000e+00\n","Epoch 14/16\n","391/391 [==============================] - 6s 15ms/step - loss: 13307905700790272.0000 - normal_output_loss: 13341328062545920.0000 - heated_output_loss: -33427652870144.0000 - normal_output_accuracy: 0.1371 - heated_output_accuracy: 0.0955 - val_loss: 18770864656875520.0000 - val_normal_output_loss: 18807440598368256.0000 - val_heated_output_loss: -36574871945216.0000 - val_normal_output_accuracy: 0.1519 - val_heated_output_accuracy: 0.0000e+00\n","Epoch 15/16\n","391/391 [==============================] - 6s 16ms/step - loss: 17013825748336640.0000 - normal_output_loss: 17057928620015616.0000 - heated_output_loss: -44112296280064.0000 - normal_output_accuracy: 0.1372 - heated_output_accuracy: 0.0949 - val_loss: 14970939586379776.0000 - val_normal_output_loss: 15024270195294208.0000 - val_heated_output_loss: -53327572238336.0000 - val_normal_output_accuracy: 0.1502 - val_heated_output_accuracy: 8.0000e-04\n","Epoch 16/16\n","391/391 [==============================] - 6s 16ms/step - loss: 21430435108093952.0000 - normal_output_loss: 21485346264973312.0000 - heated_output_loss: -54909344940032.0000 - normal_output_accuracy: 0.1383 - heated_output_accuracy: 0.0943 - val_loss: 33938260342341632.0000 - val_normal_output_loss: 34040514923724800.0000 - val_heated_output_loss: -102246746423296.0000 - val_normal_output_accuracy: 0.1455 - val_heated_output_accuracy: 0.0013\n"]}],"source":["from keras.optimizers import Adam\n","\n","# Compile the model with two losses and the Adam optimizer\n","student_distilled.compile(\n","    loss=['categorical_crossentropy', 'categorical_crossentropy'],\n","    optimizer=Adam(),\n","    metrics=['accuracy'])\n","\n","# Train the model for 25 epochs with no data augmentation\n","history = student_distilled.fit(\n","    x_train, [y_train, y_train_heated],\n","    batch_size=128,\n","    epochs=16,\n","    validation_data=(x_test, [y_test, y_test_heated])\n",")\n","\n"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Plot training and validation accuracy for each output\n","plt.plot(history.history['normal_output_accuracy'])\n","plt.plot(history.history['heated_output_accuracy'])\n","plt.plot(history.history['val_normal_output_accuracy'])\n","plt.plot(history.history['val_heated_output_accuracy'])\n","plt.title('Model Accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train Output normal', 'Train Output heated', 'Val Output normal', 'Val Output heated'], loc='lower right')\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"pW47skSN7E1_","executionInfo":{"status":"ok","timestamp":1678798954064,"user_tz":-60,"elapsed":18,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"dafd75ce-2702-4d66-a596-b6d876c89519"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"CHqcY0fYExjC"},"source":["# Intermediate supervision"]},{"cell_type":"markdown","metadata":{"id":"ewkc04e6FI7p"},"source":["In this section we will add an extra supervision coming from one of the intermediate convolutional layers. \n","1. The first thing to do is to pick, from the Teacher Net you defined above, an intermediate hint layer (e.g. the first conv layer with 64 filters);\n","2. then we can initialize a new hint_teacher model which has, as output, this hint layer. \n","3. Compile the hint_teacher model\n","4. train once again the normal_teacher model as you did above.\n","5. As before, run a prediction of the x_train x_test with the heated_teacher (to obtain y_train_heated and y_test_heated) and the hint_teacher (to obtain y_train_hint and y_test_hint)."]},{"cell_type":"code","source":["print(teacher.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWpo5wIG9rnC","executionInfo":{"status":"ok","timestamp":1678794751604,"user_tz":-60,"elapsed":35,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"ac3fbd78-4e57-438e-9261-62e33435848b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"Teacher_Net\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 32, 32, 256)  7168        ['input_1[0][0]']                \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 32, 32, 256)  590080      ['conv2d[0][0]']                 \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 32, 32, 256)  590080      ['conv2d_1[0][0]']               \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 32, 32, 256)  590080      ['conv2d_2[0][0]']               \n","                                                                                                  \n"," max_pooling2d (MaxPooling2D)   (None, 16, 16, 256)  0           ['conv2d_3[0][0]']               \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 16, 16, 128)  295040      ['max_pooling2d[0][0]']          \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 16, 16, 128)  147584      ['conv2d_4[0][0]']               \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 16, 16, 128)  147584      ['conv2d_5[0][0]']               \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 16, 16, 128)  147584      ['conv2d_6[0][0]']               \n","                                                                                                  \n"," max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 128)   0           ['conv2d_7[0][0]']               \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 8, 8, 64)     73792       ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 8, 8, 64)     36928       ['conv2d_8[0][0]']               \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 8, 8, 64)     36928       ['conv2d_9[0][0]']               \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 8, 8, 64)     36928       ['conv2d_10[0][0]']              \n","                                                                                                  \n"," max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 64)    0           ['conv2d_11[0][0]']              \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 4, 4, 32)     18464       ['max_pooling2d_2[0][0]']        \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 4, 4, 32)     9248        ['conv2d_12[0][0]']              \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 4, 4, 32)     9248        ['conv2d_13[0][0]']              \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 4, 4, 32)     9248        ['conv2d_14[0][0]']              \n","                                                                                                  \n"," flatten (Flatten)              (None, 512)          0           ['conv2d_15[0][0]']              \n","                                                                                                  \n"," dense (Dense)                  (None, 256)          131328      ['flatten[0][0]']                \n","                                                                                                  \n"," heated_teacher (Dense)         (None, 10)           2570        ['dense[0][0]']                  \n","                                                                                                  \n"," normal_teacher (Dense)         (None, 10)           2570        ['dense[0][0]']                  \n","                                                                                                  \n"," lambda (Lambda)                (None, 10)           0           ['heated_teacher[0][0]']         \n","                                                                                                  \n","==================================================================================================\n","Total params: 2,882,452\n","Trainable params: 2,882,452\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jxACUetlt9Ix"},"outputs":[],"source":["teacher_model = teacher\n","\n","hint_layer = teacher_model.layers[8] \n","\n","hint_teacher = Model(inputs=teacher_model.input, outputs=hint_layer.output)\n","hint_teacher.compile(loss='accuracy', optimizer='adam')\n","\n"]},{"cell_type":"code","source":["#base_student.fit(x_train, y_train, batch_size=64, epochs=32, validation_data=(x_test, y_test))\n","\n","history2 = teacher.fit(datagen.flow(x_train, y_train,\n","                                 batch_size=batch_size),\n","                    epochs=epochs,\n","                    validation_data=(x_test, y_test),\n","                    workers=4, callbacks=[reduce_lr])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"C_nU5OTF_qbX","executionInfo":{"status":"error","timestamp":1678799269347,"user_tz":-60,"elapsed":15,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"6fc6ac2c-1add-4f60-c1f2-4fd799e48eb4"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-54322a2cf31c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#base_student.fit(x_train, y_train, batch_size=64, epochs=32, validation_data=(x_test, y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history2 = teacher.fit(datagen.flow(x_train, y_train,\n\u001b[0m\u001b[1;32m      4\u001b[0m                                  batch_size=batch_size),\n\u001b[1;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'teacher' is not defined"]}]},{"cell_type":"code","source":["y_train_heated = heated_teacher.predict(x_train)\n","y_test_heated = heated_teacher.predict(x_test)\n","\n","y_train_hint = hint_teacher.predict(x_train)\n","y_test_hint = hint_teacher.predict(x_test)"],"metadata":{"id":"DfVPjb7Q_rob"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TccfYIb5HpJH"},"source":["Now we can deal with the Student Net: \n","1. its guided intermediate layer will be the convolutional layer with 32 filters\n","2. add, after this guided layer, another convolutional layer with 64 filters (the same shape of the Teacher Net hint layer!).\n","3. Initialize this guided_student model and compile it with mean squared error loss and mean squared error metric."]},{"cell_type":"markdown","metadata":{"id":"bfQys8Haa-4W"},"source":["The training stage is done in two steps:\n","1. we train the guided_student model (i.e. the bottom part of the student model) with y_train_hint, the ouput of the hint teacher layer.\n","2. after that, we can train the distilled_student model exactly the same way you did in the first section. "]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}