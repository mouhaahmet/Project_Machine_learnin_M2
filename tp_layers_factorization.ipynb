{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mWMM4YzOf7BH","executionInfo":{"status":"ok","timestamp":1678199776153,"user_tz":-60,"elapsed":28924,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"21512420-b3e2-46dd-951b-49f69be503c1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["\n","* Rename this notebook as PRENOM_NOM_TP_LAYER_FACTORIZATION.ipynb\n","* Delivery deadline is March the 21th\n","\n"],"metadata":{"id":"H6T4LjkWk5Ex"}},{"cell_type":"markdown","source":["The final output of the exercise will be the following pandas dataframe"],"metadata":{"id":"raGXLnQGy-BL"}},{"cell_type":"code","source":["import pandas as pd\n","results = pd.DataFrame(columns = ['model', 'matrix/Tucker rank', 'uncompressed_layer_size', 'compressed_layer_size', 'compressed_layer_size/uncompressed_layer_size', 'accuracy'])\n","results['model'] = ['baseline', 'factorization of last dense layer', 'factorization of last two dense layer', 'factorization of last conv layer', 'factorization last conv and two dense layers']\n","display(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"fmGVor5SzOg5","executionInfo":{"status":"ok","timestamp":1678199785319,"user_tz":-60,"elapsed":501,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"b7b70127-8ed4-44b1-9b85-aa6e9f71924a"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                          model matrix/Tucker rank  \\\n","0                                      baseline                NaN   \n","1             factorization of last dense layer                NaN   \n","2         factorization of last two dense layer                NaN   \n","3              factorization of last conv layer                NaN   \n","4  factorization last conv and two dense layers                NaN   \n","\n","  uncompressed_layer_size compressed_layer_size  \\\n","0                     NaN                   NaN   \n","1                     NaN                   NaN   \n","2                     NaN                   NaN   \n","3                     NaN                   NaN   \n","4                     NaN                   NaN   \n","\n","  compressed_layer_size/uncompressed_layer_size accuracy  \n","0                                           NaN      NaN  \n","1                                           NaN      NaN  \n","2                                           NaN      NaN  \n","3                                           NaN      NaN  \n","4                                           NaN      NaN  "],"text/html":["\n","  <div id=\"df-a72fc833-506a-4f33-8544-f6e6a0b168fe\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>matrix/Tucker rank</th>\n","      <th>uncompressed_layer_size</th>\n","      <th>compressed_layer_size</th>\n","      <th>compressed_layer_size/uncompressed_layer_size</th>\n","      <th>accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>baseline</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>factorization of last dense layer</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>factorization of last two dense layer</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>factorization of last conv layer</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>factorization last conv and two dense layers</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a72fc833-506a-4f33-8544-f6e6a0b168fe')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a72fc833-506a-4f33-8544-f6e6a0b168fe button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a72fc833-506a-4f33-8544-f6e6a0b168fe');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["Data preparation:\n","\n","\n","*   Download [Cifar10](https://keras.io/api/datasets/cifar10/)\n","*   Rescale images between 0 and 1,\n","*   Apply a one-hot encoding to labels of train and test set.\n","\n"],"metadata":{"id":"n_trHBxWkk2k"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.utils import to_categorical\n","\n","# Download CIFAR-10 dataset\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","# Rescale images between 0 and 1\n","x_train = x_train / 255.0\n","x_test = x_test / 255.0\n","\n","# Apply one-hot encoding to labels of train and test set\n","num_classes = 10\n","y_train = to_categorical(y_train, num_classes)\n","y_test = to_categorical(y_test, num_classes)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K_oSJ1UmgMHS","executionInfo":{"status":"ok","timestamp":1678199998043,"user_tz":-60,"elapsed":17019,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"8d84161d-b526-4fa1-cff0-c5f8e18d46f4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 3s 0us/step\n"]}]},{"cell_type":"markdown","source":["# Baseline"],"metadata":{"id":"hKCFmLy-rxEq"}},{"cell_type":"markdown","source":["Below is an implementation of a Dense layer using the Layer class ([here](https://keras.io/guides/making_new_layers_and_models_via_subclassing/) you can find the official Keras doc about custom layers)\n","\n","```\n","class Linear(keras.layers.Layer):\n","    def __init__(self, units, name):\n","        super(Linear, self).__init__()\n","        self.units = units\n","        self._name = name\n","\n","    def build(self, input_shape):\n","        self.w = self.add_weight(\n","            shape=(input_shape[-1], self.units),\n","            initializer=\"random_normal\",\n","            trainable=True)\n","        self.b = self.add_weight(\n","            shape=(self.units,), initializer=\"random_normal\", trainable=True\n","        )\n","\n","    def call(self, inputs):\n","        return tf.matmul(inputs, self.w) + self.b\n","```\n","\n"],"metadata":{"id":"nAPakc6vpFep"}},{"cell_type":"code","source":["import keras\n","class Linear(keras.layers.Layer):\n","    def __init__(self, units, name):\n","        super(Linear, self).__init__()\n","        self.units = units\n","        self._name = name\n","\n","    def build(self, input_shape):\n","        self.w = self.add_weight(\n","            shape=(input_shape[-1], self.units),\n","            initializer=\"random_normal\",\n","            trainable=True)\n","        self.b = self.add_weight(\n","            shape=(self.units,), initializer=\"random_normal\", trainable=True\n","        )\n","\n","    def call(self, inputs):\n","        return tf.matmul(inputs, self.w) + self.b"],"metadata":{"id":"uOOKTLBfunHr","executionInfo":{"status":"ok","timestamp":1678204473441,"user_tz":-60,"elapsed":257,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["Baseline implementation:\n","* implement a convolutional Neural Network having 12 convolutional layers with\n","kernel size equal to 3; the number of filters starts from 256 and is divided by 2 every 3 layers; add also MaxPooling layers every 4 convolutional layers; activation function is the ReLU and padding has to be 'same'; \n","* then, after having flattened the output of the last conv layer, add two dense layers having 500 and 10 output neurons respectively. To implement Dense layers, you can leverage the Linear class above, and use it as any regular layer. For instance:\n","\n","```\n","x = MyAwesomeCustomLayer(parameter_1, parameter_2)(x)\n","```\n","* using the parameter 'name', give a name to each layer.\n","\n","\n"],"metadata":{"id":"sQKN9RlQlp7-"}},{"cell_type":"code","source":["from tensorflow.keras import layers\n","\n","class Linear(layers.Layer):\n","    def __init__(self, units, name):\n","        super(Linear, self).__init__(name=name)\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        self.w = self.add_weight(\n","            shape=(input_shape[-1], self.units),\n","            initializer=\"random_normal\",\n","            trainable=True,\n","            name=\"weight\"\n","        )\n","        self.b = self.add_weight(\n","            shape=(self.units,),\n","            initializer=\"random_normal\",\n","            trainable=True,\n","            name=\"bias\"\n","        )\n","\n","    def call(self, inputs):\n","        return tf.matmul(inputs, self.w) + self.b\n","\n","model = tf.keras.Sequential()\n","\n","\n","\n","# Add 12 convolutional layers with kernel size equal to 3\n","num_filters = 256\n","for i in range(12):\n","    model.add(layers.Conv2D(filters=num_filters, kernel_size=3, activation=\"relu\", padding=\"same\", name=\"conv_{}\".format(i+1)))\n","    if (i+1) % 4 == 0 and (i+1)!=12 :\n","        model.add(layers.MaxPooling2D(pool_size=2, name=\"max_pool_{}\".format((i+1)//4)))\n","    if (i+1) % 3 == 0:\n","        num_filters //= 2\n","\n","# Flatten the output of the last conv layer\n","model.add(layers.Flatten())\n","\n","# Add two dense layers with 500 and 10 output neurons respectively\n","model.add(Linear(units=500, name=\"dense_1\"))\n","model.add(layers.Activation(\"relu\"))\n","model.add(Linear(units=10, name=\"dense_2\"))\n","\n","# Output layer with softmax activation\n","#model.add(layers.Activation(\"softmax\"))\n","\n","# Build the model\n","model.build(input_shape=(None, 32, 32, 3))\n","\n","# Print the model summary\n","model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l9mu287EgwkB","executionInfo":{"status":"ok","timestamp":1678204516722,"user_tz":-60,"elapsed":783,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"13485674-45c3-482b-a897-864e93435f67"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv_1 (Conv2D)             (None, 32, 32, 256)       7168      \n","                                                                 \n"," conv_2 (Conv2D)             (None, 32, 32, 256)       590080    \n","                                                                 \n"," conv_3 (Conv2D)             (None, 32, 32, 256)       590080    \n","                                                                 \n"," conv_4 (Conv2D)             (None, 32, 32, 128)       295040    \n","                                                                 \n"," max_pool_1 (MaxPooling2D)   (None, 16, 16, 128)       0         \n","                                                                 \n"," conv_5 (Conv2D)             (None, 16, 16, 128)       147584    \n","                                                                 \n"," conv_6 (Conv2D)             (None, 16, 16, 128)       147584    \n","                                                                 \n"," conv_7 (Conv2D)             (None, 16, 16, 64)        73792     \n","                                                                 \n"," conv_8 (Conv2D)             (None, 16, 16, 64)        36928     \n","                                                                 \n"," max_pool_2 (MaxPooling2D)   (None, 8, 8, 64)          0         \n","                                                                 \n"," conv_9 (Conv2D)             (None, 8, 8, 64)          36928     \n","                                                                 \n"," conv_10 (Conv2D)            (None, 8, 8, 32)          18464     \n","                                                                 \n"," conv_11 (Conv2D)            (None, 8, 8, 32)          9248      \n","                                                                 \n"," conv_12 (Conv2D)            (None, 8, 8, 32)          9248      \n","                                                                 \n"," flatten_6 (Flatten)         (None, 2048)              0         \n","                                                                 \n"," dense_1 (Linear)            (None, 500)               1024500   \n","                                                                 \n"," activation_12 (Activation)  (None, 500)               0         \n","                                                                 \n"," dense_2 (Linear)            (None, 10)                5010      \n","                                                                 \n","=================================================================\n","Total params: 2,991,654\n","Trainable params: 2,991,654\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["\n","\n","*   Initialize this (uncompressed) baseline model\n","*   Compile it by choosing a categorical crossentropy loss, Adam optimizer and accuracy metrics,\n","*   train it for 40 epochs with an appropriate [data augmentation](https://keras.io/zh/examples/cifar10_resnet/) strategy; it might be helpful to reduce the learning rate programmatically with the callback   [ReduceLROnPlateau](https://keras.io/api/callbacks/reduce_lr_on_plateau/).\n","\n"],"metadata":{"id":"q4Dqx7jTrENo"}},{"cell_type":"code","source":["from tensorflow.keras.callbacks import ReduceLROnPlateau\n","# Compile the model\n","model.compile(\n","    loss=\"categorical_crossentropy\",\n","    optimizer=tf.keras.optimizers.Adam(),\n","    metrics=[\"accuracy\"]\n",")\n","\n","\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","batch_size = 64\n","epochs = 5\n","\n","# Define data augmentation strategy\n","train_datagen = ImageDataGenerator(\n","    rotation_range=15,\n","    zoom_range=0.2,\n","    horizontal_flip=True\n",")\n","\n","\n","# Train Teacher Net model with normal output\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=0.00001)\n","\n","# history = teacher.fit(train_datagen.flow(x_train, [y_train, y_train], batch_size=batch_size),\n","#                       steps_per_epoch=len(x_train) / batch_size, epochs=epochs,\n","#                       validation_data=(x_val, [y_val, y_val]), callbacks=[reduce_lr])\n","\n","history = model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n","                        validation_data=(x_test, y_test),\n","                        epochs=epochs, verbose=1, workers=4,\n","                        )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XwUh9bDNlAp6","executionInfo":{"status":"ok","timestamp":1678204893560,"user_tz":-60,"elapsed":370091,"user":{"displayName":"mouhamadou lamine cisse","userId":"07608170929179924100"}},"outputId":"16b075e6-fe23-46c7-d72e-4e9823af9db7"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-28-3730989d7d74>:31: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  history = model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n"]},{"output_type":"stream","name":"stdout","text":["782/782 [==============================] - 66s 78ms/step - loss: 9.5890 - accuracy: 0.0954 - val_loss: 9.6709 - val_accuracy: 0.0921\n","Epoch 2/5\n","782/782 [==============================] - 61s 77ms/step - loss: 9.6709 - accuracy: 0.0954 - val_loss: 9.6709 - val_accuracy: 0.0921\n","Epoch 3/5\n","782/782 [==============================] - 61s 78ms/step - loss: 9.6709 - accuracy: 0.0950 - val_loss: 9.6709 - val_accuracy: 0.0921\n","Epoch 4/5\n","782/782 [==============================] - 61s 77ms/step - loss: 9.6709 - accuracy: 0.0952 - val_loss: 9.6709 - val_accuracy: 0.0921\n","Epoch 5/5\n","782/782 [==============================] - 61s 78ms/step - loss: 9.6708 - accuracy: 0.0955 - val_loss: 9.6709 - val_accuracy: 0.0921\n"]}]},{"cell_type":"markdown","source":["Before going to the next section, we need to implement a function, called count_layer_weights, that will allow us to count the number of parameters of a given layer for a given model:\n","* this function has 2 parameters: the model and the layer name,\n","* it returns the number of weights for the chosen layer.\n","* to build the function, you might find helpful to check out the two lines of code here below\n","\n","```  \n","for layer in my_model.layers:\n","  print(layer.name, layer.count_params())\n","```\n","\n"],"metadata":{"id":"g5dixPLCu0ls"}},{"cell_type":"markdown","source":["# Factorizing dense layers"],"metadata":{"id":"fuw2qSx2rmJl"}},{"cell_type":"markdown","source":["Taking as an inspiration the Linear class above, implement a MatrixFactorization class.\n","\n","\n","*   a Matrix factorization layer will be characterized by 3 parameters: number of units, matrix rank and layer name\n","*   The operation implemented by this layer is $y = Ax + b= W_1W_2x + b = W_1(W_2x) + b$ where the dimension shared by $W_1$ and $W_2$ is determined by the rank parameter.\n","\n"],"metadata":{"id":"39cJL_fbr91n"}},{"cell_type":"markdown","source":["\n","\n","1.   choose a matrix rank and replace the last dense layer of the baseline with an instance of the MatrixFactorization layer,\n","2.   initialize this model, compile and train it by following the same protocol of the baseline;\n","3. fill the \"results\" dataframe appropriately (you can use the function count_layer_weights to get the compressed and uncompressed layer size),\n","4. repeat from 1. to 3. for a new model where **both** dense layers are factorized. \n","\n","\n","\n"],"metadata":{"id":"9GFmlNFS1GsZ"}},{"cell_type":"markdown","source":["# Factorizing convolutional layers"],"metadata":{"id":"rRa8gJMW2bmy"}},{"cell_type":"markdown","source":["To compress a convolutional layer with Tucker factorization we have to implement a function called conv_tucker_factorization. This function is characterized as follows:\n","\n","\n","*   it has four parameters: the input, the two Tucker ranks, denoted by $R_3$ and $R_4$ and the final number of convolutional filters $T$\n","*   the operation done by this layer can be implemented by stacking three convolutional layer: the first layer is a poitwise convolution with $R_3$ filters; the second one is a 3x3 convolution with $R_4$ filters; the third one is a pointwise convolution with $T$ filters.\n","* do not forget to add non-linearity only after the last convolution. \n","\n"],"metadata":{"id":"6iwYowTp5GUb"}},{"cell_type":"markdown","source":["Repeat points 2. and 3. described above for a model where the last convolutional has been Tucker-factorized with rank of your choice.\n","\n","\n","Eventually, you can factorize the **both Dense and the convolutional layers**.\n","Copy here below your \"results\" Dataframe filled with the results you obtained."],"metadata":{"id":"A_ntAqF-9BDu"}}]}